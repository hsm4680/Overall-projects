{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsm4680/Overall-projects/blob/master/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOvwsqRWyO7y"
      },
      "source": [
        "\n",
        "###Word2vec\n",
        " 단어를 벡터화하면 단어의 '문맥적 의미'를 보존할 수 있으며, 유사한 단어들끼리는 모이 단어 벡터들의 코사인 유사도 등을 통해 얼마나 단어들이 가까운 의미를 지녔는지 측정할 수 있다. 단어의 관계도 알 수 있는데 유명한 예시인 king - man + woman = queen 처럼, 벡터 계산을 통해 이를 찾아낼 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2MemS5uygNF"
      },
      "source": [
        "### Word2vec의  2가지 구현 방법\n",
        "하나는 CBOW(continuous bag of words)이고 다른 하나는 skip-gram이다. skip-gram의 성능이 조금 더 좋으므로 skip-gram을 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNAaLqiszCwN"
      },
      "source": [
        "위의 문장이 있다고 할 때 우리는 특정 '윈도우 사이즈'를 정해서 문장에서 윈도우를 옮겨가며 가운데 있는 것을 타겟 워드, 나머지는 컨텍스트 워드라고 정한다. \n",
        "\n",
        "만약에 윈도우 사이즈를 1로 하면 target 단어의 왼쪽, 오른쪽 단어가 context 단어가 된다. 그러면 이를 (context, target) 쌍으로 만들어보면 다음과 같은 결과를 얻을 수 있다.\n",
        "\n",
        "([the, brown], quick), ([quick fox], brown), ([brown, jumped], fox), …\n",
        "\n",
        "​\n",
        "\n",
        "skip-gram 의 목표는 현재 target word가 주어졌을 때 context word가 나올 확률을 최대화하는 것이다.  아래와 같은 objective funtion을 통해 이를 해줄 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVqLxpylnpFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adc0dcb-d9e0-4491-f4c4-3d542773abea"
      },
      "source": [
        "# google colab의 드라이브를 불러와 코드에 반영하기 위한 드라이브 마운트 작업\n",
        "# [보기] > [목차]를 선택하면 아래 코드가 자동 삽입되나 지금은 구글 드라이브와 연동하여 gdrive 사용\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D46h061ZkpXQ"
      },
      "source": [
        "# os 모듈은 Operation System의 약자로, 운영체제에서 제공되는 기능을 파이썬에서 수행할 수 있게 함.\n",
        "# 파이썬을 이용해 파일을 복사하거나 디렉토리를 생성하고, 특정 디렉토리 내의 파일을 불러오는 등으로 사용됨.\n",
        "\n",
        "import os\n",
        "# os.chdir 함수는 R에서 setwd()와 동일한 역할을 하여 현재 디렉토리를 ''로 변경함.\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "# os.getcwd()는 현재 디렉토리(Current Working Directory)의 경로를 출력함.\n",
        "current_path = os.getcwd()\n",
        "# os.path.join()은 현재 디렉토리의 절대경로/catdog을 출력함.\n",
        "main_dir = os.path.join(current_path, '2021-data-creator-camp-1030-1')\n",
        "# os.makedirs는 지정된 경로에 맞게 디렉토리를 생성함.\n",
        "# os.mkdir()는 새로운 하위 폴더 하나만을 생성할 수 있음.\n",
        "# os.makedirs()는 경로에 지정된 모든 폴더를 생성함.\n",
        "# exist_ok = True는 해당 경로에 폴더가 실제로 존재하는 경우에는 그냥 넘어가고, 없는 경우에만 생성하게 함.\n",
        "os.makedirs(main_dir, exist_ok=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GK_pMCYoW-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ab0f24-9523-48c4-9b39-543fab1f9a7b"
      },
      "source": [
        "# 경고(Warning)는 코드는 작동하나 의도하지 않은 결과일 수 있음을 알릴 때 출력되는 메시지임.\n",
        "# 복잡한 작업일수록 이러한 경고 메시지가 뜰 가능성이 높지만 깔끔한 결과 제시를 방해하는 요소일 때가 많음.\n",
        "# 간단한 경고 필터를 설정해 이러한 경우를 어느 정도 방지함.\n",
        "import warnings \n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# matplotlib에서 제공하는 그래프에서 간혹 마이너스(-) 기호가 깨질 때, 이를 표시되게 수정하는 코드\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "## Random Seed 고정\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "random_state = 42\n",
        "seed_everything(random_state)\n",
        "\n",
        "# 팀 이름 설정\n",
        "team_name = '진리관227호'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# numpy, pandas, matplotlib은 파이썬 데이터 분석의 3대장 격으로 각각 np, pd, plt의 명칭으로 임포트함.\n",
        "\n",
        "# numpy는 데이터 분석을 용이하게 하기 위한 ndarray(np.array) 구조를 지원하여 행렬 연산을 가능하게 함.\n",
        "import numpy as np # linear algebra\n",
        "# pandas는 파이썬 데이터 분석에 필수적인 패키지로 시리즈, 데이터프레임, 패널 데이터 형태를 지원함.\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "# matplotlib는 파이썬의 시각화 기능을 주로 담당하는 패키지로 거의 모든 형태의 플롯 생성이 가능함.\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# seaborn은 matplotlib과 함께 파이썬의 대표적인 시각화 도구로, 그래프 스타일 설정 면에서 강점이 있음.\n",
        "# 정교한 그래프 크기 조절이나 범례 값 조정 시에는 matplotlib을 함께 사용해야 함.\n",
        "import seaborn as sns\n",
        "\n",
        "# Random 모듈은 random() 함수로 대표되며 난수 생성에 주로 이용됨.\n",
        "import random\n",
        "\n",
        "# %matplotlib inline은 브라우저 상에서 바로 결과를 확인할 수 있게 함.\n",
        "%matplotlib inline\n",
        "\n",
        "# nltk는 파이썬에서 자연어 처리 및 문서 분석을 담당하는 텍스트마이닝 핵심 패키지임.\n",
        "# 말뭉치, 토큰 생성, 형태소 분석, 품사 태깅 등의 기능을 제공함.\n",
        "import nltk\n",
        "# NLTK 라이브러리 기반 문장 / 단어 구분을 위해 관련 기능을 추가함.\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "# 불용어(stopword)는 큰 의미가 없는 단어 토큰으로, 문장에서 자주 등장하나 분석에 도움이 되지 않는 단어로 미리 정의됨.\n",
        "nltk.download('stopwords')\n",
        "# punkt는 텍스트 파일을 문장 단위로 분해하는 Sentence Tokenize에 활용되는 모델로, 약어(Ph.D.의 .)와 마침표(.) 등을 구분함.\n",
        "nltk.download('punkt')\n",
        "# 다운로드된 불용어 토큰을 임포트하여 분석에 활용할 수 있게 함.\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# BeautifulSoup는 웹 페이지에 해당하는 HTML 문서를 탐색해 원하는 부분만 뽑아낼 수 있게 만들어진 라이브러리임.\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 파이썬에서 정규표현식을 사용하기 위해 필요한 모듈(Regular Expression의 약어), 기본 설치됨.\n",
        "import re\n",
        "\n",
        "\n",
        "## Model\n",
        "# 데이터를 훈련 데이터와 평가 데이터로 구분하기 위해 이용함.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 인공신경망, 딥러닝 모델에서는 변수들이 0과 1 사이의 범위로 변환되어 있어야 함.\n",
        "# MinMaxScaler 메서드는 위와 같은 역할을 수행할 수 있음.\n",
        "# StandardScaler는 평균과 표준편차에 근거해 데이터를 표준화함.\n",
        "# (만약 이상치가 강하게 의심되는 경우 중앙값과 IQR에 근거한 RobustScaler를 사용할 수 있음.)\n",
        "# Categorical 데이터는 데이터가 수치가 아니며, 이는 기계학습 모델이 받아들일 수 없는 형태임.\n",
        "# LabelEncoder는 Categorical 데이터를 Numerical 데이터로 변환하는 기능을 수행함.\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "\n",
        "# 로지스틱 회귀분석과 랜덤 포레스트를 사용하기 위한 임포트\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 분류 성능을 측정하기 위한 평가 지표를 임포트하는 부분.\n",
        "# accuracy : 전체 평가 데이터에서 맞게 예측한 데이터의 비율 ((TP + TN) / Total)\n",
        "# f1 : 정밀도(Precision), 재현율(Recall)이 주로 1로 치우친다는 점을 고려해 한쪽으로 치우치지 않을 때 점수가 올라가는 평가 지표.\n",
        "# confusion_matrix : 목표 변수의 원래 클래스와 예측한 클래스가 일치하는지를 혼동행렬로 표현할 수 있음.\n",
        "# roc_auc_score : ROC 곡선 아래 면적에 기반한 점수, TPR이나 FPR을 복합적으로 고려하여 평가함.\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "# 위의 모델은 로지스틱 회귀, 랜덤 포레스트 등 기계학습을 위한 임포트임.\n",
        "# 아래 부분은 Keras와 관련 함수에 기반해 같은 분류 작업을 딥러닝으로 수행하기 위한 임포트임.\n",
        "\n",
        "import keras\n",
        "# One-Hot Encoding은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에만 1을 부여하는 형태임.\n",
        "# Tokenizer는 단어의 빈도 수를 계산하기 위한 목적 등으로 사용되는 정수 인코딩을 지원함.\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "# 길이가 동일한 문서들은 하나의 행렬로 인식해 병렬 작업이 가능함. 따라서 문장의 길이를 맞추면 작업 속도가 상승함.\n",
        "# pad_sequences()는 정수 인코딩을 거친 데이터에 대해 가장 길이가 긴 문장을 기준으로 벡터의 차원을 잡고 빈 부분을 0으로 채움.\n",
        "# 이때, 문서의 앞에 0을 채우므로 뒤에 채우고 싶다면 padding = \"post\" 인자를 추가해야 함.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 일반적인 다층 퍼셉트론 신경망, 특히 이미지 분석은 단계적으로 입력층 - 은닉층 - 출력층을 쌓아나감.\n",
        "# Sequential은 위처럼 model.add()에 기반한 단계적인 층 쌓기에 적합한 방법론임.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Dense : 모든 노드 사이에 연결선이 형성되는 Fully Connected Layer인 Dense 레이어를 사용하게 하는 함수\n",
        "# Flatten : 2차원 데이터를 Fully Connected Layer에 적용할 수 있도록 1차원으로 바꾸는 함수\n",
        "# Embedding : 문자 입력에 대한 학습을 담당하는 Layer로, 단어를 의미론적 기하공간에 매핑할 수 있도록 벡터화시키는 역할을 담당함.\n",
        "# LSTM : 순환 신경망을 구성하는 레이어로, 과거의 출력 데이터를 재귀적으로 참조하는 방식으로 기능함.\n",
        "# SpatialDropout1D : 공간적인 드롭아웃을 지원하는 함수로, dropout이 잘 먹히지 않는 상황에서 대안으로 사용됨.\n",
        "# Input : 입력층을 별도로 정의하기 위해 사용하는 함수\n",
        "# Bidirectional : LSTM의 양방향 수행을 지원하는 함수로, LSTM 내에서 순행과 역행 참조를 모두 가능하게 함.\n",
        "# Dropout : 어떤 레이어의 모든 노드에서 나가는 Activation을 제거하여 과적합을 방지하는 함수\n",
        "from keras.layers import Dense, Flatten, Embedding, LSTM, SpatialDropout1D, Input, Bidirectional,Dropout\n",
        "\n",
        "# EarlyStopping은 학습 진행 도중 손실 함수가 더 이상 줄어들지 않는 조건에서 실행되며 학습을 자동으로 중단함.\n",
        "# ReduceLROnPlateau는 학습 진행 도중 평가 지표가 더 이상 향상되지 않는 조건에서 실행되며 학습률을 자동으로 조정함.\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Keras 기반 딥러닝 모형의 과적합을 막기 위한 L2 규제 (Ridge Regression)를 도입하는 부분.\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcnUEfS503MU"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ci3XbTqzdmL"
      },
      "source": [
        "Word2vec은 label 되지 않은 데이터를 통해서도 훈련할 수 있기 때문에 요번에는 labeled과 unlabeled train data를 모두 사용하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt0P6kqnjnz3"
      },
      "source": [
        "# Pandas에서 제공하는 read_csv는 R과 동일한 역할을 수행함.\n",
        "# header = 0은 첫번째 행이 변수명임을 의미함. delimiter = \"\\t\" 이므로 구분자는 tab이며, quoting = 3에 따라 큰따옴표는 무시됨.\n",
        "raw_train_data_labeled = pd.read_csv(main_dir+'/labeledTrainData.tsv', header=0,delimiter=\"\\t\", quoting=3)\n",
        "raw_test_data = pd.read_csv(main_dir+'/testData.tsv', header=0,delimiter=\"\\t\", quoting=3)\n",
        "raw_train_data_unlabeled = pd.read_csv(main_dir+'/unlabeledTrainData.tsv', header=0,delimiter=\"\\t\", quoting=3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAhFcqspU_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e56b8d7d-d0d0-4d9c-c425-cc76f38968c1"
      },
      "source": [
        "raw_train_data_labeled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TrCalB1qWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "c2406490-88d7-48aa-cec1-b47f3a05e0f3"
      },
      "source": [
        "raw_train_data_unlabeled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPMc6wwGnwQn"
      },
      "source": [
        "unlabeled 의 경우 sentiment가 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30trUXunu3Kq"
      },
      "source": [
        "X = raw_train_data_labeled['review']\n",
        "y = raw_train_data_labeled['sentiment']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5ZSxhbUlNi"
      },
      "source": [
        "review_data = X.append(raw_test_data['review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKL9xeZEUmu4",
        "outputId": "073e7cfa-aaf5-41bb-c30a-5c85d8cf9fa9"
      },
      "source": [
        "review_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sALjfT17UpFn"
      },
      "source": [
        "ntrain = X.shape[0]\n",
        "df = raw_train_data_labeled.append(raw_test_data, sort=False)\n",
        "df = df.drop(['sentiment'], axis=1)\n",
        "df_review = df['review']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGe7A69UUyRB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "fda38fad-64ea-46a2-d0ed-ba8dd323f1c7"
      },
      "source": [
        "'''\n",
        "Here we will do preprocessing\n",
        "1. Removing punctuations\n",
        "2. Lowering all words\n",
        "3. removing non-alphabet things\n",
        "4. removing stop words\n",
        "5. Tokenizing the sentence\n",
        "'''\n",
        "# string은 자주 사용하는 문자열(알파벳 대소문자, 숫자 등)을 다수 저장하고 있음.\n",
        "import string\n",
        "\n",
        "# lines는 위에서 큰따옴표로 묶인 문장들을 각각 리스트의 element로 변환해 저장함.\n",
        "review_lines = list()\n",
        "lines = review_data.values.tolist()\n",
        "\n",
        "# 단어 형태이면서 불용어가 아닌 소문자 토큰만을 남겨 review_lines에 저장하는 부분.\n",
        "for line in lines:\n",
        "    \n",
        "    '''\n",
        "    breaks line into it's sub parts like each word and comma etc,\n",
        "    https://pythonspot.com/tokenizing-words-and-sentences-with-nltk/\n",
        "    '''\n",
        "    tokens = word_tokenize(line)   \n",
        "    \n",
        "     #convert to lower case\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    \n",
        "    #remove punctuation from each word\n",
        "    # brief detail: https://pythonadventures.wordpress.com/2017/02/05/remove-punctuations-from-a-text/\n",
        "    table = str.maketrans('','', string.punctuation)\n",
        "    stripped = [w.translate(table) for w in tokens]\n",
        "     \n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    words = [w for w in stripped if w.isalpha()]\n",
        "    \n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    \n",
        "    review_lines.append(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1ba9e1dccc64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# lines는 위에서 큰따옴표로 묶인 문장들을 각각 리스트의 element로 변환해 저장함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mreview_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'review_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Yuan7QwDFG"
      },
      "source": [
        "### Word2vec 모델 트레이닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJbCqNXh3vVF"
      },
      "source": [
        "인자로 여러가지 선택을 전달해 줄 수 있다. 주요하게 바꿀 수 있는 요소들은 다음과 같다.\n",
        "\n",
        "​\n",
        "\n",
        "architecture: skip-gram (slower, better for infrequent words) vs CBOW (fast)\n",
        "\n",
        "the training algorithm: hierarchical softmax (better for infrequent words) vs negative sampling (better for frequent words, better with low dimensional vectors)\n",
        "\n",
        "sub-sampling of frequent words: can improve both accuracy and speed for large data sets (useful values are in range 1e-3 to 1e-5)\n",
        "\n",
        "dimensionality of the word vectors: usually more is better, but not always\n",
        "\n",
        "context (window) size: for skip-gram usually around 10, for CBOW around 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVHvTHaATqLJ"
      },
      "source": [
        "#### word2vec 방식을 통한 모델링\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "911CW6w-Ah9V",
        "outputId": "f189deef-926a-4ff4-b0d9-0e68c6cb4d05"
      },
      "source": [
        "# gensim과 word2vec를 이용해 모델링하는 부분임.\n",
        "\n",
        "'''\n",
        "gensim is python library for training word embeddings in given data\n",
        "for more information visit: \n",
        "1. https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "2. http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XEoWKVwzbIV\n",
        "'''\n",
        "# 문장 내 각 토큰들끼리의 의미를 고려하여 단어를 벡터로 변화시킴.\n",
        "# 이 결과를 토대로 Embedding Layer에 적용하여 NLP Task를 수행할 수 있음.\n",
        "\n",
        "# sentences : 학습시킬 문장\n",
        "# size : 각 단어에 대해 변환될 벡터의 차원\n",
        "# workers : 실행할 병렬 프로세스 코어 수\n",
        "# min_count : 단어의 최소 빈도수, 이보다 작은 빈도의 단어는 무시됨.\n",
        "# window : 문맥 윈도우 수 (양쪽으로 몇 개까지의 단어를 고려해 의미 파악)\n",
        "embedding_vector_size = 150\n",
        "# now training embeddings for each word \n",
        "model_2 = gensim.models.Word2Vec(sentences = review_lines, size=embedding_vector_size, min_count=1, window=5, workers=4 )\n",
        "\n",
        "# to get total number of unique words\n",
        "words = list(model_2.wv.vocab)\n",
        "\n",
        "print(\"vocab size:\", len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-ad550e8b254a>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    model_1 = gensim.models.(sentences = review_lines, size=embedding_vector_size, min_count=1, window=5, workers=4 )\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mlL87EGTuLC"
      },
      "source": [
        "#### FastText 를 통한 모델링\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUIkkZ0_U7V_",
        "outputId": "d2cccd62-4c63-4a02-e03e-7f411f9137cc"
      },
      "source": [
        "'''\n",
        "gensim is python library for training word embeddings in given data\n",
        "for more information visit: \n",
        "1. https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
        "2. http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XEoWKVwzbIV\n",
        "'''\n",
        "import gensim\n",
        "from gensim.models import FastText\n",
        "\n",
        "embedding_vector_size = 150\n",
        "# now training embeddings for each word \n",
        "model_1 = FastText(sentences = review_lines, size=embedding_vector_size, min_count=1, window=5, workers=4 )  # FastText를 import 하고, word2vec 대신 FastText 함수를 넣으면 돌아간다.\n",
        "\n",
        "# to get total number of unique words\n",
        "words = list(model_1.wv.vocab)\n",
        "\n",
        "print(\"vocab size:\", len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 134197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "tDxetJFGVyrZ",
        "outputId": "c2238ced-afe1-4238-8303-6100066379a0"
      },
      "source": [
        "#len(sequence)\n",
        "leng=0\n",
        "length = [(leng + len(x)) for x in review_lines]\n",
        "plt.hist(length)\n",
        "plt.xlabel('length of words')\n",
        "plt.ylabel('frequency')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZOr3IyfwdgN"
      },
      "source": [
        "### 모델 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uj91m_UI49L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8cefb98-ccce-4aaf-e568-338c0256fd36"
      },
      "source": [
        "import math\n",
        "avg_length = sum(length)/len(review_lines)\n",
        "\n",
        "# if words are more than max_length then they are skipped, if less than padding with 0 is done\n",
        "print(avg_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122.12676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zP5kgmaI75u"
      },
      "source": [
        "#max_len = math.ceil(avg_length)             # this is used to decide how many words in seq to keep\n",
        "max_len = math.ceil(avg_length) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tWllsdUI-56"
      },
      "source": [
        "#  Embedding Vector가 만들어졌으면 길이를 맞춰 병렬연산을 수행하는 작업을 거침.\n",
        "\n",
        "'''\n",
        "Now we have trained the embeddings, we now have embedding vector for each word. We will\n",
        "convert our text training data to numeric using theseword embeddings.\n",
        "First, we need to make length of each input same, therefore we'll do padding. But padding happends \n",
        "on numeric data, therefore we'll convert texts to sequences using tokenize() function. Then add padding\n",
        "Then we'll replace each non-zero numeric resulted from texts to sequences to its corresponding word\n",
        "embedding.\n",
        "'''\n",
        "\n",
        "# 단어를 토큰화하여 가장 빈도가 높은 단어부터 총 6,000개의 단어를 분석에 활용함.\n",
        "# 이후 이를 벡터 형태로 표현하고, pad_sequences를 통해 길이를 동일하게 함.\n",
        "max_features = 6000\n",
        "tokenizer = Tokenizer(num_words=max_features)       #keeps 6000 most common words\n",
        "train_test_data = review_lines                       # contains word tokens extracted from lines\n",
        "tokenizer.fit_on_texts(train_test_data)\n",
        "sequence = tokenizer.texts_to_sequences(train_test_data)\n",
        "train_test_data = pad_sequences(sequence, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQkwQLLOK1sz"
      },
      "source": [
        "# Preparing embedding matrix\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_vector_size))\n",
        "# +1 is done because i starts from 1 instead of 0, and goes till len(vocab)\n",
        "for  word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = model_1.wv[word]\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4r9UCPCJBBr"
      },
      "source": [
        "X = train_test_data[:ntrain,:]\n",
        "X = np.append(X,train_test_data[ntrain+25000: ,:])\n",
        "X = X.reshape(-1,123)\n",
        "y1 = y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fzqVa6sLmoN"
      },
      "source": [
        "# 파티셔닝을 통해 훈련 데이터와 평가용 데이터를 구분하는 부분.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y1, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ztnM0C4Lgpo"
      },
      "source": [
        "# Sequential()을 모델로 선언했으므로 이후 레이어들은 모두 순차적으로 결합됨.\n",
        "model = Sequential()\n",
        "# 문자 입력에 대한 학습을 진행하는 레이어로, 데이터를 벡터화하는 과정을 거침.\n",
        "# input_dim : 단어 사전의 크기, 학습하고자 하는 단어 수와 동일해야 함.\n",
        "# output_dim : 출력 차원\n",
        "# input_length : 한 번에 학습하고자 하는 문장의 길이 (Flatten 레이어가 있다면 반드시 그 직전)\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = embedding_vector_size, \n",
        "                    input_length = max_len, weights = [embedding_matrix]))\n",
        "# 앞에서부터 단어를 처리하는 순방향 RNN + 뒤에서부터 처리하는 역방향 RNN\n",
        "# 둘을 결합하면 양방향 RNN (Bidirectional RNN)이 됨.\n",
        "# 64개의 노드를 갖고, 이중 0.25에 해당하는 노드가 비활성화됨.\n",
        "# 또한 순환 드롭아웃(Recurrent Dropout)을 통해 순환층의 과대적합을 방지함.\n",
        "model.add(Bidirectional(LSTM(64, dropout=0.25, recurrent_dropout=0.1)))\n",
        "# 10개의 전결합층 형성, 드롭아웃은 0.3으로 0.3에 해당하는 노드가 비활성화됨.\n",
        "model.add(Dense(10))\n",
        "model.add(Dropout(0.3))\n",
        "# 최종 출력은 1 또는 0이며 그에 따라 시그모이드 활성화 함수를 취함.\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfaHmhCBW6fG"
      },
      "source": [
        "# 현재 학습률을 조정하기 위해 모니터링하는 대상은 성과 지표임. val_loss로 손실 함수를 볼 수 있음.\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            # 지정한 수만큼의 기간에서 성능 향상이 일어나지 않으면 학습률을 조정함.\n",
        "                                            patience=3, \n",
        "                                            # verbose = 1이면 에포크마다 학습 진행사항을 출력하며, 0이면 과정을 출력하지 않음.\n",
        "                                            verbose=1, \n",
        "                                            # 학습률 조정에 사용되는 새로운 값으로, factor * 기존 학습률 = 새 학습률이 됨.\n",
        "                                            factor=0.5, \n",
        "                                            # 학습률의 하한선으로, 이보다 낮은 학습률로 조정되지 않음.\n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma8FLxGOy-q4"
      },
      "source": [
        "### 딥러닝\n",
        "#### RMSProp \n",
        " 기울기를 단순 누적하지 않고 지수 가중 이동 평균 Exponentially weighted moving average 를 사용하여 최신 기울기들이 더 크게 반영되도록 하였다.\n",
        "\n",
        " #### Adam\n",
        " RMSProp와 Momentum 기법을 합친 optimizer. Momentum에서 관성계수 m과 함께 계산된 V_t 로 parameter를 업데이트하지만 Adam에서는 기울기 값과 기울기의 제곱값의 지수이동평균을 활용하여 step변화량을 조절한다.\n",
        "\n",
        " 두 방법간 비교해본 결과, 큰 차이는 나타나지 않았음. 비교적 Adam이 로스가 적은듯?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKnvaU2wW86a",
        "outputId": "f67ec4b8-6396-496a-a080-ef3b44d9e358"
      },
      "source": [
        "# 여기서는 학습 이전에 학습과 관련된 설정을 수행하며, 특히 손실 함수와 최적화 방법을 정의함.\n",
        "\n",
        "# 문제의 유형, 출력층의 활성화 함수, 손실 함수는 서로 연계되어 있음.\n",
        "# 본 데이터는 Cat과 Dog을 분류하는 Binary Classification Problem Type임.\n",
        "# 그에 따라 출력층의 활성화 함수는 Sigmoid, 손실 함수는 binary_crossentropy를 사용함.\n",
        "\n",
        "# 옵티마이저는 케라스 모델의 컴파일에 필요한 또다른 요소이며, 여러 종류가 있음.\n",
        "# 대부분의 CNN 기반 이미지 분류 문제에서 rmsprop을 사용하는데 이유는 당장 알 수 없음.\n",
        "\n",
        "# 메트릭은 평가 기준을 말하며, 일반적인 평가 기준으로 accuracy를 사용함.\n",
        "# 손실 함수와 함꼐 훈련 과정 모니터링에 사용되는 두 지표임.\n",
        "model.compile(optimizer='RMSProp', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())\n",
        "\n",
        "# 이미지가 아닌 일반적인 텍스트 데이터로 제네레이터를 따로 사용하지 않았음.\n",
        "# X_train, Y_train : 훈련 데이터셋을 제공함.\n",
        "# Epoch : 전체 데이터셋에 대한 학습 반복 횟수를 지정함.\n",
        "# batch_size : n개의 예측값마다 실제값과 비교하여 가중치를 수정함.\n",
        "# validation_data : 검증용 데이터셋을 제공함.\n",
        "# callbacks : 손실 함수가 감소하지 않거나, 학습률이 더 증가하지 않을 경우를 대비한 Callback Function을 선언함.\n",
        "history = model.fit(X_train, y_train, epochs = 15, batch_size = 700, validation_data=(X_test, y_test),callbacks = [learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 123, 150)          20129700  \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              110080    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,241,081\n",
            "Trainable params: 20,241,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "29/29 [==============================] - 128s 4s/step - loss: 0.5804 - acc: 0.6941 - val_loss: 0.5099 - val_acc: 0.7546 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "29/29 [==============================] - 117s 4s/step - loss: 0.4559 - acc: 0.7965 - val_loss: 0.4496 - val_acc: 0.8018 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "29/29 [==============================] - 118s 4s/step - loss: 0.4177 - acc: 0.8228 - val_loss: 0.3895 - val_acc: 0.8376 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "29/29 [==============================] - 117s 4s/step - loss: 0.3903 - acc: 0.8335 - val_loss: 0.3730 - val_acc: 0.8486 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "29/29 [==============================] - 117s 4s/step - loss: 0.3740 - acc: 0.8411 - val_loss: 0.3467 - val_acc: 0.8600 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "29/29 [==============================] - 122s 4s/step - loss: 0.3490 - acc: 0.8536 - val_loss: 0.3391 - val_acc: 0.8624 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "29/29 [==============================] - 118s 4s/step - loss: 0.3384 - acc: 0.8596 - val_loss: 0.3599 - val_acc: 0.8502 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "29/29 [==============================] - 119s 4s/step - loss: 0.3186 - acc: 0.8674 - val_loss: 0.3336 - val_acc: 0.8618 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.3058 - acc: 0.8734\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "29/29 [==============================] - 117s 4s/step - loss: 0.3058 - acc: 0.8734 - val_loss: 0.3471 - val_acc: 0.8592 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "29/29 [==============================] - 118s 4s/step - loss: 0.2747 - acc: 0.8875 - val_loss: 0.3191 - val_acc: 0.8766 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "29/29 [==============================] - 122s 4s/step - loss: 0.2706 - acc: 0.8917 - val_loss: 0.3360 - val_acc: 0.8658 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "29/29 [==============================] - 119s 4s/step - loss: 0.2623 - acc: 0.8962 - val_loss: 0.3265 - val_acc: 0.8744 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "29/29 [==============================] - ETA: 0s - loss: 0.2567 - acc: 0.8985\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "29/29 [==============================] - 119s 4s/step - loss: 0.2567 - acc: 0.8985 - val_loss: 0.3167 - val_acc: 0.8732 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "29/29 [==============================] - 118s 4s/step - loss: 0.2425 - acc: 0.9054 - val_loss: 0.3275 - val_acc: 0.8758 - lr: 2.5000e-04\n",
            "Epoch 15/15\n",
            "29/29 [==============================] - 119s 4s/step - loss: 0.2420 - acc: 0.9042 - val_loss: 0.3268 - val_acc: 0.8768 - lr: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fq_AeSpTXDtf",
        "outputId": "32871bbd-0be2-487a-808f-590bfc27e67b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bn38e+dmcyQhAQSQphHmUUQsSgqoFS0to5YtbXYo/ZYa32rp2pb29Payam1joeqdarVWlFRcEYEhCTKjMyBTBAyD2Ta+37/WBsIYWeC7OwM9+e6cmXtNezcibJ+ez3Pep4lqooxxhjTWIC/CzDGGNM5WUAYY4zxygLCGGOMVxYQxhhjvLKAMMYY41WQvwtoL/Hx8ZqWlubvMowxpkvJyMg4pKoJ3rZ1m4BIS0sjPT3d32UYY0yXIiJZTW2zJiZjjDFeWUAYY4zxygLCGGOMV92mD8Kburo6srOzqa6u9ncpPhcWFkZKSgrBwcH+LsUY001064DIzs4mKiqKtLQ0RMTf5fiMqlJYWEh2djaDBg3ydznGmG6iWzcxVVdXExcX163DAUBEiIuL6xFXSsaYjtOtAwLo9uFwRE/5PY0xHadbNzEZY0xnUFlTz+c7D7Etv5xewYFEhAYRERpIREjQseXQICJDgwgPcdYHBPj/Q58FhI+VlJTw0ksvcfPNN7fpuAsvvJCXXnqJ2NhYH1VmjPGlfYVVfLTtAB99XcCaXYXUutxtOj48JJDwkCAiPeHhhEnDZWdbeGgQKb17MX9c/3b/HSwgfKykpIS//e1vJwREfX09QUFN//mXLl3q69KMMe2ozuUmI6uYj7cd5MNtB9l5sAKAwfERXDt9ILNH9mXSwN7UudxU1riorK2nsqaeipp6qjyvjyxX1DjbKmtdzveaeipr6zlUUUtWYZXnWOcYVZiUGtv1AkJE5gKPAIHAM6r6QKPtA4HFQAJQBCxU1WzPtuuAezy7/kZVn/Nlrb5y1113sWvXLiZMmEBwcDBhYWH07t2bbdu2sX37di655BL2799PdXU1t912G4sWLQKOTR1SUVHBvHnzOOuss1i1ahXJycm8+eab9OrVy8+/mTGmqLKWT7cf5MOtB1mxvYCy6nqCA4UzBsVx1dRUzh3Zl0HxEccdExYcSFRY+9yOrqocrnNRV++bJ4P6LCBEJBB4DDgfyAbWicgSVd3SYLc/Ac+r6nMici7wO+BaEekD/AKYAiiQ4Tm2+GTr+dVbm9mSW3ayh3s1un80v/jmmGb3eeCBB9i0aRNfffUVn3zyCRdddBGbNm06ejvq4sWL6dOnD4cPH+b000/nsssuIy4u7rj32LFjBy+//DJPP/00l19+Oa+//joLFy5s19/FGNMyVWVbfjkfbTvIR9sOkrmvGFWIjwxlzpgkZo/qy4yh8e0WAC0REcJDgiDEN+/vyyuIqcBOVd0NICKvAAuAhgExGviJZ/lj4D+e5TnA+6pa5Dn2fWAu8LIP6+0QU6dOPW6swqOPPsobb7wBwP79+9mxY8cJATFo0CAmTJgAwOTJk9m7d2+H1WtMT3e41sWqXYeOhkJeqXM7+biUGP773GGcO7IvpyXHdIpO5fbmy4BIBvY3eJ0NnNFon/XAt3CaoS4FokQkroljkxv/ABFZBCwCSE1NbbaYlj7pd5SIiGOXm5988gkffPABq1evJjw8nFmzZnkdyxAaGnp0OTAwkMOHD3dIrcb0RC63klN8mE93FPDR1gOs2lVITb2biJBAzhoWz+3nDWfWiAT6Rof5u1Sf83cn9U+Bv4rI9cAKIAdwtfZgVX0KeApgypQpvmmEO0VRUVGUl5d73VZaWkrv3r0JDw9n27ZtrFmzpoOrM6bnqHO5OVRRw8GyGg6UVXOwvMb5OrpczYGyGgoranB7ziYD48K5+gynL2HqoD6EBgX695foYL4MiBxgQIPXKZ51R6lqLs4VBCISCVymqiUikgPManTsJz6s1Wfi4uKYMWMGY8eOpVevXiQmJh7dNnfuXJ544glGjRrFiBEjmDZtmh8rNaZrqql3UXD0ZO+c6I98P1DmrC8or6awshZt9DFSBOIiQkmMDqVvVChj+sWQGB1KYkwY0wbHMTg+okcPQhVt/BdrrzcWCQK2A7NxgmEdcLWqbm6wTzxQpKpuEflfwKWq93k6qTOASZ5dM4HJR/okvJkyZYo2fmDQ1q1bGTVqVHv+Wp1aT/t9Tc+iquSWVrMpp5TNOaVsyi1jc24pB8pqTtg3MECIjwyhb1QYidGhJESF0TcqlMRo53vfaGc5LiKEoMBuP6FEs0QkQ1WneNvmsysIVa0XkVuBZTi3uS5W1c0icj+QrqpLcK4SficiitPEdIvn2CIR+TVOqADc31w4GGO6F1VlX1EVm3LK2JhTyubcUjbllFJcVQdAgMCwvlHMGBJPWnzE0ZN/gufkHxcRSmA37DTuaD7tg1DVpcDSRuvua7D8GvBaE8cuxhkjYYzpxlxuZc+hCjbllLEpp5RNuaVszi2jvLoegOBAYXhiFHPGJDEmOYax/aMZmRRNr5Ce1R/gD/7upDbG9CB1Ljc7D1Y4zUS5TiBsySujqta5NyU0KIBR/aJZMKE/Y/vHMDY5hmGJkT2uc7izsIAwxvhEaVUd2/LL2JZfzrb8MrbklrE1v5zaemdOovCQQMb0j+byKQMYmxzD2ORohiZE9vg+gc7EAsIYc0rqXG52F1SyLb+MrXnlfO0JhSMDygBiw4MZmRTFddMHesIghrS4COsn6OQsIIwxraKqHCyvca4I8pwQ2JpXxq6CCupczt2QwYHCkIRIzhjUh5H9ohmZFMXIpGgSo0N79O2iXZUFhI+d7HTfAA8//DCLFi0iPDzcB5UZ07TDtS62Hyg/1kSU5ywfuYsIICk6jJH9opg1oq8TBP2iGBwfSUiQNRF1FxYQPtbUdN+t8fDDD7Nw4UILCNMh6l1u/rEmi3+syWLPocqjg8p6BQcyPMm5i8gJAufKIDbcRzPEmU7DAsLHGk73ff7559O3b19effVVampquPTSS/nVr35FZWUll19+OdnZ2bhcLu69914OHDhAbm4u55xzDvHx8Xz88cf+/lVMN5a5r5h73tjElrwypqb14Zvj+jOqn9M8lNonvFtORGda1nMC4t27IH9j+75n0mkw74Fmd2k43ffy5ct57bXXWLt2LarKxRdfzIoVKygoKKB///688847gDNHU0xMDA8++CAff/wx8fHx7Vu3MR7FlbX8Ydk2Xl67n6ToMP52zSTmjU2y/gID9KSA6ASWL1/O8uXLmThxIgAVFRXs2LGDmTNncscdd/Czn/2M+fPnM3PmTD9Xaro7t1v5V8Z+Hnh3G2XV9fxg5iBuO284kaF2SjDH9Jz/G1r4pN8RVJW7776bm2666YRtmZmZLF26lHvuuYfZs2dz3333eXkHY07dltwy7vnPRjL3lTBlYG9+c+lYRiZF+7ss0wn1nIDwk4bTfc+ZM4d7772Xa665hsjISHJycggODqa+vp4+ffqwcOFCYmNjeeaZZ4471pqYTHsor67jofd38NzqvcT0CuaP3x7HZZNSrH/BNMkCwscaTvc9b948rr76aqZPnw5AZGQkL7zwAjt37uTOO+8kICCA4OBgHn/8cQAWLVrE3Llz6d+/v3VSm5Omqry9IY9fv72Fgooarp6ayp1zRthdSKZFPpvuu6PZdN897/c1LdtdUMF9b25m5c5DjE2O5jeXnMaEAbH+Lst0In6Z7tsY4z/VdS4e+3gnT366m9DgAO5fMIZrzhhoU1uYNrGAMKab+WjbAX6xZDP7iw5z6cRk7r5wJH2juv/zk0376/YBoao94p7u7tJUaE5ednEV97+1heVbDjC0byQv/2Aa04fEte1N8tbD9mUw5lKIH+abQo3D7Yb6w1BbBXWVnu9VUFvZ6HtT2xusjx8Gl/yt3Uvs1gERFhZGYWEhcXFx3TokVJXCwkLCwuxTYk9UW+/m/1bu4dEPdwDws7kj+f5Zg9o2J5IqrH0alv8cXLXw8W9h1HyYcTukTPZR5d2Q2wUVB6A0B8qOfOVCabazXHHw2Am+rqqNby4QEgHB4RASDsERzveQCAjzTb9Stw6IlJQUsrOzKSgo8HcpPhcWFkZKSoq/yzAdbPWuQu59cxM7D1YwZ0wi931zDMmxvdr2JtWl8OatsHUJDJsDF/waNrwK656GrW9B2kyY8WMYOhs60wetkn2w+Q2oKYeQSAiNhJAo53tolGdd1LFtwREQcAoTCbrdUHnw+JN/abYTAGU5zvryPFDX8ccFhUF0MsQkw4AznBO6txN9cHgT6z3fg8I6/O/fre9iMqY7Kq2qY82eQt7ekMdb63MZ0KcXv7p4DOeOTGz7m+Vkwms3OCe62b+A6bceO4nWlEPGc7D6MSjPhcTTYMZtTvNToJ8+W9ZUwJY3Yf3LsPczZ50EgLpbcbA0CJLIBkESdeK6oDDn0/5xJ/9ccNcf/5aBoc6JP/rIV3/P6xTPcgr06t25grWR5u5isoAwppMrq65j3Z4iVu8qZPXuQrbklaHqzLJ648xB3DxraNufz6wKa5+CZT+HyET4zt9hwFTv+9bXwsZX4fNH4NB2iE2F6T+CiQudT7a+5nY5YfDVy85VTl0V9BkM46+CcVc49dRVOeFRW+EEW025Z7kCaj2vm9xeATVlx5Zdtc7PDQxxTvJHTv4Ng+DIcnhcpz75t4YFhDFdSGVNPev2FrF6dyFrdhWyMacUt0JIUACTUmOZPjie6UPiGD8g5uSe1Xy4BJbc6jQfDZ/ndG6G92n5OLcbtr8LKx+G7LXOyXHqTTD1B607vq0O7YCvXoIN/3Q+xYfGwNhLYfzVTpj56sRcXwN1hyE0+tSapLoICwhjOrHDtS4ysopZvfsQq3cVsiG7lHq3EhwoTBgQy/TBcUwbEsek1N6EBZ9EIDSUkwH/usE54Z73K5h+S9tPtKqwb7UTFDuWOW3mk65z3it2wKnVV1UEm//tXC3kpDvNR0PPg/FXwogLIbiN/SumRRYQxnQi1XUuvtxXcvQK4cv9xdS5lMAAYVxKDNMHxzF9SBxTBvZpe9NRU1Thiydg+b0QlQTf/jsMOP3U3/fAFqfpadNrzuux33b6KRJHt/49XHWw8wPnamH7e04TT98xMOEqOO1yiDqJvhXTahYQxvhRbb2b9dklTh/CrkIy9hVTW+8mQOC05BimDYlj2uA4Tk/r45vptg8XO3cpbXu7bU1KbVGy3+nMznzO6Q8YNgfO+jGkTvd+haIK+RucK4WN/4KqQxAeD6d9xwmGpHFdvm2/q7CAMKaD1da7WbmzgLc35PH+5gOU19QjAqP7RR+9Qjh9UB+iw4J9W0h2Brx2vXM3zvn3w7SbfXvirSpyxlOsfRKqCiFlqhMUw+c57fnlB5wO769ehoObnY7g4XNhwtVOU1Kgj/8e5gQWEMZ0gDqXm893HuKdDXks25xPWXU90WFBzB2bxLkjE5k2uE/HzaB6XJNSP+cupRSv5wDfqK2CL1+A1X9xxivEj3DuNtr1kTNOIHmK068w9jLfdHCbVrPJ+ozxkXqXmzW7i3h7Qy7vbc6npKqOqNAgzh+TyDfH9WfG0Pi2jWhuDw2blEZcBJc85tyL35FCwuGMRTDle85gtlWPwqGvnf6J8VdBwvCOrcecFAsIY9rI5Va+2FPIOxvyeG9TPoWVtUSEBHL+6EQuGtefs4fHn9ztp+0hOwP+db0zonfO72Daf/m3LT8wCMZ9x/kyXY4FhOk66qqhIh/K8pwRrQNndNh96m63sm5vEe9szGPpxnwOVdTQKziQ2aP6Mn9cf2aNSDj1W1BPhSqs+Ru8f58zuOt7y2wOJXPKLCCM/7ldUFngfOoty3O+H/kqy4PyfGf5cNHxxyWOhXPvheFzfPIp2e1WvtxfzFvr83h3Ux4HymoIDQrg3JFOKJw7sm/Lt6Hmb4JVf3FG6nobjRvVD4JCT63QqiJ48xb4eimMnA8L/trxTUqmW7KAML5VU+7M83PCyT/fubOmPN+Z/bLxBGcS4EwBEZUEvdMgdZpzMo3u56yrPASfPAAvX+FMgDb7Pkg765TLVVW+2l/COxvyWLoxj9zSakKCApg1PIGLxvXjvFGJRLTmVtT8TfDp752pIUKinA7arM+difEai+jrZT6flGPL0f2bvrtn/zpnLqXyfJj7AJzxQ7s91LQbu4vJ+EbRHlj5oDP4qfEEZ2GxzkkvKgmiPN+j+zkBcGRdRELLE8K56pw7ZT79gzOR2pBznaDoP7FNpR6Z/G71rkLe33KAnJLDBAcKZw9LYP54JxSiWns7av5GTzC85UzVMO2/nK8jn+hrKjwTwGV7ZgX1LJflHpsltKas0ZuKE5ZHJ4LzfNWUO3/j6P7wnWch2ZqUTNvZba6m4xzaCZ/92Zk/JyAIJl0LA8/0nPw9AdDe0yXUHYZ1z8BnDzrNUKMuhnPvgYQRXnevqKln3Z4iVu06xOrdhWzOdSa/CwsOYNrgOC46rR8XjEkiplcb7slvKRjaorrMS3A0CpHaCmffkfNhwWPQy54zbU6OBYTxvYPb4LM/wabXnSmQp3wPzvyRc2XQUarLnNG8q//qjOYdfxXMuovD4clH5zpa5ZnryOVWQgIDmJgay/QhcZw5JP7kJr9rz2Boi+pSZ9K92FRrUjKnxALC+M6BzbDij7D5P86kbad/3wmGyL5+K6m2rIDC935HwtZ/gLp5yXUej9YtoDgglvEpMUcDYVJq75Of6yhvgxMM2972BMPNMO2H1jlsuhwbKGfaX956p+1/29tOJ+zMn8C0WyCijc9Abgf1Ljcbc0pZtauQNbsLWbe3iOq62fSTCdwX/Q4La97nmpBPcZ3xQ0Jm/vjUmmOOC4YY+MZdFgym27KAMG2TnQEr/uDMunnkBHnGTR06XYKqsiWvjNW7Clm1q5C1e4qoqHE6wkckRnHl6alMHxLHtEFxxIR/Fwp3wce/JXDVQ5C52Hl85hk3OY93bK3GwTDrbueOIWv7N92YNTGZ1tn3hXOC3PWh82l5+i0wdRGExXRoGRlZRfxu6TbSs4oBGBwfwbQhcZzpmRE1PrKZMQX5G+Gj3zjhFpkIZ9/pPMcgqJn5kRoHw/SbLRhMt+K3PggRmQs8AgQCz6jqA422pwLPAbGefe5S1aUikgZsBb727LpGVX/Y3M+ygPCRvSudE+SeFc50zGfeCqff6Dy3twPtPFjBH5dtY9nmAyREhXLrOUOZMyaJpJiwtr/Zvi/gw/sha6XTyTvrf2Dc5RDQoD+iYROaBYPpxvwSECISCGwHzgeygXXAVaq6pcE+TwFfqurjIjIaWKqqaZ6AeFtVx7b251lAtCNV2POpc4LM+twZyDXjNphyQ9uaZdrBwbJqHvpgB6+m7ycsKICbvjGEG2cOIjzkFFtHVZ2ZRT+8H/K+goSRzq2xsamNguEWpznKgsF0U/7qpJ4K7FTV3Z4iXgEWAFsa7KNAtGc5Bsj1YT2mJaqw80PniiF7rTNuYe7vYfJ1Hf6ox/LqOp5asZtnPttDncvNtdMGcuu5Q5tvQmoLERg62xlct3WJ0/T0z4XOtrAY56rCgsH0cL4MiGRgf4PX2cAZjfb5JbBcRH4ERADnNdg2SES+BMqAe1T1s8Y/QEQWAYsAUlNT26/ynsbtdtrlV/wBcr+EmAFw0Z9hwkIIPokmnFNQW+/mpS+yePSjnRRV1jJ/XD/unDOCgXE+unIRgdELnGmxN73uPNlswjUWDMbg/7uYrgKeVdU/i8h04B8iMhbIA1JVtVBEJgP/EZExqnrcHASq+hTwFDhNTB1dfJfnqnceEL/yITi4BWIHwjcfdQaYNddx6wNut/L2xjz+tOxr9hVVMX1wHHfNG8n4AR10og4MgvFXdMzPMqaL8GVA5AADGrxO8axr6PvAXABVXS0iYUC8qh4EajzrM0RkFzAcsE6G9lBXDV+9AJ8/CiVZkDAKLn0Kxn7LL498XLXzEL97dxsbc0oZmRTF3284nVnDExAbIWyMX/kyINYBw0RkEE4wXAlc3WiffcBs4FkRGQWEAQUikgAUqapLRAYDw4DdPqy1Z6gug/TFznMDKg44j32c+7tjzwvuYFvzynjg3W18ur2A/jFh/Pk747lkYjKBARYMxnQGPgsIVa0XkVuBZTi3sC5W1c0icj+QrqpLgDuAp0XkdpwO6+tVVUXkbOB+EakD3MAPVbWoiR9lWlJ5CNY8DuuedubwGXwOXPYMpM30yzw+2cVVPPj+dt74MofosGD+58KRfHd6mn8fuGOMOYENlOvOSvY7D6vJfB7qq2HUfDjrJ5A8yT/lVNXy2Mc7eW51FgA3nJnGzbOGEhPe8c1axhiHzcXU0xRsh88fdqbcBhh3hTO9hJ8eFF9d5+LZVXv528c7Ka+p57JJKdx+/nCSYzv21lljTNtYQHQnOZnOA2S2vg1BYc6I5+m3QuyAlo/1gYqaet7ZkMvDH+wgr7Sac0Yk8LN5IxmZFN3ywcYYv7OA6OpUYe9nzsNydn/sjP49+6fOtBAR8R1eTunhOj7YcoB3N+WzYkcBtfVuxqfE8ODlE5g+pONnejXGnDwLiK7K7Ybt7zrBkJPuTIdx3q+cB/WEdewn9MKKGt73hMKqXYeocyn9YsK4emoq88YmMXVQH7tl1ZguyAKiq3HVOyN+Vz4EBVudwW1+GPV8sKyaZZvzWboxny/2FOJWSO0TzvdmDGLu2CTGp8QSYLerGtOlWUB0Nf/5IWz8F/QdDd96GsZ8yxkF3AGyi6t4b1M+723KJ2NfMaowJCGCm2cNZe7YJMb0j7YrBWO6EQuIrmTbO044zPwpnPPzDhnctvdQJe9uyufdTXlsyC4FYGRSFLefN5x5Y5MYltix034bYzqOBURXcbgE3v4JJI6FWXf5NBx2HChn6UYnFLbllwMwPiWGn80dybyxSaTFd+yU38YY/7CA6CrevxcqD8LVr/hkvqTtB8pZ8lUu727KY1dBJSIwObU391w0irljk0jpHd7uP9MY07lZQHQFuz9xRkPPuA36T2y3t1VVVu8q5IkVu1mxvYAAgWmD47j+zDTmjEmib3THTvVtjOlcLCA6u9pKeOs26DMEZt3dLm9Z73Lz7qZ8nlyxi005ZcRHhnLnnBFcefoA4trrgTzGmC7PAqKz+/i3ULwXrl96yk91q6qt59V1+3lm5R6yiw8zOD6C333rNC6dmGwT5RljTmAB0ZllpztTc0/5PqTNOOm3OVRRw/Or9vL8mixKquqYPLA3984fzfmjEm2sgjGmSRYQnVV9Lbx5q/Nc6PN+eVJvsedQJU9/tpvXM7Kpdbk5b1QiN509mClpfdq1VGNM92QB0VmtfNAZKX31q22eOiNzXzFPfbqbZVvyCQ4I4LLJydw4czBDEiJ9VKwxpjuygOiMDmyBFX+C0y6H4XNadYjbrXy07SBPrdjN2r1FRIcFcfOsIVx3Zhp9o+xuJGNM21lAdDZuF7x5i3PVMPeBFnevqXfx5pe5PPXZbnYerCA5thf3zh/NFacPIDLU/vMaY06enUE6mzWPQ24mXPZ/ENH09Nilh+t48Yssnv18LwfLaxjVL5qHr5jAReP6ERzY8c+XNsZ0PxYQnUnRbvjoNzB8Hoy9zOsuhypqeOKTXby8dh+VtS7OGhrPn74znpnD4m2iPGNMu7KA6CxUYcl/O9NozH8QvJzsS6pqueLJ1ewtrOKi0/qx6OzBjE2O8UOxxpiewAKis8h83nky3Dcfgej+J2yurnPxg+fT2V90mBdvPINpg+3pbMYY37KA6AzKcmH5PZA2EyZdd8Jmt1u549X1rNtbzF+ummjhYIzpENab6W+q8M4d4Kpzrh68NC39dulW3tmYx88vHMU3x594dWGMMb5gAeFvm9+Ar5fCuT+HuCEnbF68cg/PrNzD9WemcePMQX4o0BjTU1lA+FNlISy9E/pPgjP+64TN727M49fvbGHOmETunT/a7lIyxnQo64Pwp2V3Q3UJLFhywnOl0/cWcds/v2LigFgeuXIigTapnjGmg9kVhL9sXw4b/gkz74DEMcdt2lVQwY3Pp5Mc24tnrjvdpuI2xviFBYQ/VJfB27dDwignIBo4WF7NdYvXEhQgPHfDVPpEhPipSGNMT2dNTP7w4a+gLAdu/ACCjj3BrbKmnu8/m05hRS2vLJpGapw9B9oY4z92BdHRslbBumdg2s2QMuXo6nqXm1teymRzbimPXTOR8QNi/VikMcbYFUTHqjvsPAQodqBzW6uHqnLPfzbxydcF/PbS0zh3ZKIfizTGGIcFREf69PdQtAu++yaERBxd/dePdvLKuv3ces5Qrj4j1Y8FGmPMMdbE1FFyv4LPH4WJ18LgWUdX/yt9P39+fzvfmpTMHRcM91t5xhjTmAVER3DVOU1LEQlwwW+Orl6xvYC7/72Rs4bG88C3xtlAOGNMp2JNTB3h80fgwEa44kXo5XQ+b84t5eYXMxnaN5LHF04iJMiy2hjTubTqrCQit4lItDj+T0QyReQCXxfXLRRsd/oexlwKo+YDkFNymBv+vo6osCCevWEqUWHBfi7SGGNO1NqPrd9T1TLgAqA3cC3Q8gOTezq3G5bc6nRIz/sDAKVVdVy/eC2H61w8e8NUkmLC/FykMcZ419ompiON4xcC/1DVzWIN5i1b9wzs/wIufRIi+1JT72LRP9LJKqziue9NZURSlL8rNMaYJrX2CiJDRJbjBMQyEYkC3C0dJCJzReRrEdkpInd52Z4qIh+LyJciskFELmyw7W7PcV+LyJzW/kKdRsl++OCXMPQ8GHcFbrfy039t4Is9RfzxO+OYPsQe+mOM6dxaewXxfWACsFtVq0SkD3BDcweISCDwGHA+kA2sE5ElqrqlwW73AK+q6uMiMhpYCqR5lq8ExgD9gQ9EZLiqutryy/nVp78Hdz3MfwhE+P27W3lrfS53zRvJggnJ/q7OGGNa1NoriOnA16paIiILcU7spS0cMxXYqaq7VbUWeAVY0GgfBaI9yzFArmd5AfCKqtao6h5gp+f9uobiLFj/Mky+HmJTeW7VXp5csZvvTh/ITWcP9nd1xhjTKq0NiMeBKhEZD9wB7IPClyQAABJrSURBVAKeb+GYZGB/g9fZnnUN/RJYKCLZOFcPP2rDsYjIIhFJF5H0goKCVv4qHWDlQyABMOM23tuUzy/f2sz5oxP5xTfH2FgHY0yX0dqAqFdVxflk/1dVfQxojx7Wq4BnVTUFTwe4iLR6QICqPqWqU1R1SkJCQjuU0w5Ks+HLF2DitWSUhHPbK18yYUAsj9pDf4wxXUxr+yDKReRunNtbZ3pO4i3dvJ8DDGjwOsWzrqHvA3MBVHW1iIQB8a08tnNa+TAA+eP+ixufXUe/mDCe+e4UeoXYQ3+MMV1Laz+tXwHU4IyHyMc5Yf+xhWPWAcNEZJCIhOB0Oi9ptM8+YDaAiIwCwoACz35XikioiAwChgFrW1mr/5TlQuZzMOFqluwNoLiqjmeuO524yNCWjzXGmE6mVQHhCYUXgRgRmQ9Uq2qzfRCqWg/cCiwDtuLcrbRZRO4XkYs9u90B/EBE1gMvA9erYzPwKrAFeA+4pUvcwfT5o+B2wcyfkL63mIFx4QztG+nvqowx5qS0qolJRC7HuWL4BGfQ3F9E5E5Vfa2541R1KU7nc8N19zVY3gLMaOLY/wX+tzX1dQrlByDj7zD+KjR2IJn7dnD28E7SL2KMMSehtX0QPwdOV9WDACKSAHwANBsQPcqqR8FVCzN/wr6iKg5V1DJ5YG9/V2WMMSettX0QAUfCwaOwDcd2fxUFkL4YTrsc4oaQkVUMYAFhjOnSWnsF8Z6ILMPpJwCn03ppM/v3LKv/6jxO9OyfApCRVUxUaBDD+tpcS8aYrqtVAaGqd4rIZRzrL3hKVd/wXVldSGUhrH0axl4G8cMAJyAmpMbauAdjTJfW6gcGqerrwOs+rKVrWvM3qKs6evVQXl3H1wfKmTs2yc+FGWPMqWk2IESkHGe+pBM2Aaqq0V629RyHi+GLJ2H0Aug7CoCv9pegav0Pxpiur9mAUFVrRG/OmiegthzOvvPoqoysYkRgwoBYPxZmjDGnzu5EOlnVpbDmcRg5H5LGHl2dkVXMiMQoe4yoMabLs4A4WV88BTWl8I3/d3SVy618ta/EmpeMMd2CBcTJqCl3bm0dPg/6jT+6esfBcspr6i0gjDHdggXEyVj7NFSXwDfuPG51+l4bIGeM6T4sINqqpsK5ehh6PiRPPm5TZlYx8ZGhpPYJ91NxxhjTfiwg2ip9MVQVHtf3cETGvmImD4y1p8YZY7oFC4i2qK1yJuUbfA4MOP4R2QXlNWQVVlnzkjGm27CAaIuMZ6GyAL7xsxM2Ze6z/gdjTPdiAdFadYfh84chbSYMnH7C5sysYkICAxjTP8YPxRljTPuzgGitzH9AxQGvVw/gDJAbmxxNWLA9e9oY0z1YQLRGfQ2sfAhSz4S0s07YXFPvYkNOqTUvGWO6FQuI1vjyBSjPde5c8nKH0ubcMmrr3RYQxphuxQKiJfW1ztVDylQYPMvrLpmeJ8hNSrWAMMZ0HxYQLVn/MpTud/oemhjfkJFVzIA+vegbHdbBxRljjO9YQDTHVQef/Rn6T4Khs73uoqqkZxUz2a4ejDHdjAVEcza8CiVZzV49ZBcfpqC8xvofjDHdjgVEU1z18NmfIGkcDJ/T5G4ZWUcGyPXpqMqMMaZDtPqZ1D3OptehaDdc8WKTVw/gBERESCAjkuzhe8aY7sWuILxxu2DFHyFxLIy4sNldM7KKmZjam8AAm6DPGNO9WEB4s/kNKNzhPGs6oOk/UUVNPdvyy5hk/Q/GmG7IAqIxt9u5ekgYCaMubnbX9ftLcKtN0GeM6Z4sIBrbugQKtrV49QBO85IITBgQ20HFGWNMx7GAaOjI1UPcMBhzaYu7Z2QVM7xvFDG9gjugOGOM6VgWEA19vRQObPJcPTQ/K6vbrWTuK7b+B2NMt2UBcYQqfPp76DMYxl7W4u47Cyoor663/gdjTLdlAXHE9mWQvwFm/hQCWx4ecmyAnAWEMaZ7soCAY1cPsQNh3OWtOiR9bzF9IkJIiwv3cXHGGOMfFhAAOz+E3EyYeQcEtq7DOXNfMZNSeyPNjLI2xpiuzAJCFT59AGIGwPirWnVIYUUNew5VMiXNmpeMMd2XBUTRbsjfCGfdDkEhrTokc18JYP0PxpjuzaeT9YnIXOARIBB4RlUfaLT9IeAcz8twoK+qxnq2uYCNnm37VLX5Yc0nK24I3LYBerV+sFtGVjHBgcJpyTE+KckYYzoDnwWEiAQCjwHnA9nAOhFZoqpbjuyjqrc32P9HwMQGb3FYVSf4qr7jRCW2affMrGLG9I8hLLj5sRLGGNOV+bKJaSqwU1V3q2ot8AqwoJn9rwJe9mE97aK23s367BJrXjLGdHu+DIhkYH+D19medScQkYHAIOCjBqvDRCRdRNaIyCW+K7NttuSVUVPvtoAwxnR7neWBQVcCr6mqq8G6gaqaIyKDgY9EZKOq7mp4kIgsAhYBpKamdkihNkDOGNNT+PIKIgcY0OB1imedN1fSqHlJVXM833cDn3B8/8SRfZ5S1SmqOiUhIaE9am5RZlYxybG9SIwO65CfZ4wx/uLLgFgHDBORQSISghMCSxrvJCIjgd7A6gbreotIqGc5HpgBbGl8bEdTVdKziuzqwRjTI/isiUlV60XkVmAZzm2ui1V1s4jcD6Sr6pGwuBJ4RVW1weGjgCdFxI0TYg80vPvJX3JLqzlQVmMBYYzpEXzaB6GqS4Gljdbd1+j1L70ctwo4zZe1nYz0vUWA9T8YY3oGG0ndBplZxYSHBDIyKcrfpRhjjM9ZQLRBxr5iJgyIJSjQ/mzGmO7PznStVFlTz9a8cmteMsb0GBYQrbQ+uwSXW+0Ro8aYHsMCopUyPQPkJg2wgDDG9AwWEK2UkVXMsL6RxIS37oFCxhjT1VlAtILbrWTuswn6jDE9iwVEK+w+VEHp4TrrfzDG9CgWEK1gE/QZY3oiC4hWyMgqJjY8mMHxEf4uxRhjOowFRCukZxUzObU3IuLvUowxpsNYQLSgqLKW3QWV1v9gjOlxLCBa8OU+638wxvRMFhAtyMgqJihAGJ8S6+9SjDGmQ1lAtCAjq5gx/aPpFRLo71KMMaZDWUA0o87lZn12ifU/GGN6JAuIZmzNK6O6zm39D8aYHskCohk2QM4Y05NZQDQjI6uY/jFh9Ivp5e9SjDGmw1lANCMzq9j6H4wxPZYFRBNySw6TW1ptzUvGmB7LAqIJmTZAzhjTw1lANCF9bzFhwQGM6hft71KMMcYvLCCakLmvmPEpsQQH2p/IGNMz2dnPi6raejbnllnzkjGmR7OA8GJDdikut1pAGGN6NAsIL44MkJuUagFhjOm5LCC8yMwqZkhCBL0jQvxdijHG+I0FRCOqSsa+YmteMsb0eBYQjew+VElJVZ0FhDGmx7OAaMQm6DPGGIcFRCOZWcXE9ApmcHykv0sxxhi/soBoJCOrmEmpsQQEiL9LMcYYv7KAaKC0qo4dByuseckYY7CAOM6RCfpsim9jjLGAOE5GVjGBAcL4lFh/l2KMMX5nAdFARlYxo/pFEREa5O9SjDHG7ywgPOpdbr7aX8Jkm17DGGMAHweEiMwVka9FZKeI3OVl+0Mi8pXna7uIlDTYdp2I7PB8XefLOgG25ZdzuM7F5LQ+vv5RxhjTJfisLUVEAoHHgPOBbGCdiCxR1S1H9lHV2xvs/yNgome5D/ALYAqgQIbn2GJf1WsD5Iwx5ni+vIKYCuxU1d2qWgu8AixoZv+rgJc9y3OA91W1yBMK7wNzfVgrGVnFJEWH0T8mzJc/xhhjugxfBkQysL/B62zPuhOIyEBgEPBRW44VkUUiki4i6QUFBadUbEaWM0GfiA2QM8YY6Dyd1FcCr6mqqy0HqepTqjpFVackJCSc9A/PL60mp+SwjX8wxpgGfBkQOcCABq9TPOu8uZJjzUttPfaUHRkgZ/0PxhhzjC8DYh0wTEQGiUgITggsabyTiIwEegOrG6xeBlwgIr1FpDdwgWedT2RkFRMaFMDoftG++hHGGNPl+OwuJlWtF5FbcU7sgcBiVd0sIvcD6ap6JCyuBF5RVW1wbJGI/BonZADuV9UiX9WanlXM+JRYQoI6S4ubMcb4n0+HDKvqUmBpo3X3NXr9yyaOXQws9llxHtV1LjbnlHLjzMG+/lHGGNOl9PiPzGXVdVw0rh8zh8X7uxRjjOlUevykQ32jwnjkyon+LsMYYzqdHn8FYYwxxjsLCGOMMV5ZQBhjjPHKAsIYY4xXFhDGGGO8soAwxhjjlQWEMcYYrywgjDHGeCUNpkDq0kSkAMg6hbeIBw61Uzm+1pVqha5Vb1eqFbpWvV2pVuha9Z5KrQNV1evzErpNQJwqEUlX1Sn+rqM1ulKt0LXq7Uq1QteqtyvVCl2rXl/Vak1MxhhjvLKAMMYY45UFxDFP+buANuhKtULXqrcr1Qpdq96uVCt0rXp9Uqv1QRhjjPHKriCMMcZ4ZQFhjDHGqx4fECIyV0S+FpGdInKXv+tpjogMEJGPRWSLiGwWkdv8XVNLRCRQRL4Ukbf9XUtLRCRWRF4TkW0islVEpvu7pqaIyO2e/wc2icjLIhLm75oaEpHFInJQRDY1WNdHRN4XkR2e7739WeMRTdT6R8//BxtE5A0RifVnjQ15q7fBtjtEREWkXR6R2aMDQkQCgceAecBo4CoRGe3fqppVD9yhqqOBacAtnbxegNuArf4uopUeAd5T1ZHAeDpp3SKSDPw3MEVVxwKBwJX+reoEzwJzG627C/hQVYcBH3pedwbPcmKt7wNjVXUcsB24u6OLasaznFgvIjIAuADY114/qEcHBDAV2Kmqu1W1FngFWODnmpqkqnmqmulZLsc5gSX7t6qmiUgKcBHwjL9raYmIxABnA/8HoKq1qlri36qaFQT0EpEgIBzI9XM9x1HVFUBRo9ULgOc8y88Bl3RoUU3wVquqLlfVes/LNUBKhxfWhCb+tgAPAf8PaLc7j3p6QCQD+xu8zqYTn3AbEpE0YCLwhX8radbDOP/Duv1dSCsMAgqAv3uaxJ4RkQh/F+WNquYAf8L5pJgHlKrqcv9W1SqJqprnWc4HEv1ZTBt8D3jX30U0R0QWADmqur4937enB0SXJCKRwOvAj1W1zN/1eCMi84GDqprh71paKQiYBDyuqhOBSjpPE8hxPG33C3BCrT8QISIL/VtV26hzf32nv8deRH6O07T7or9raYqIhAP/A9zX3u/d0wMiBxjQ4HWKZ12nJSLBOOHwoqr+29/1NGMGcLGI7MVpujtXRF7wb0nNygayVfXIFdlrOIHRGZ0H7FHVAlWtA/4NnOnnmlrjgIj0A/B8P+jnepolItcD84FrtHMPGBuC82FhveffWwqQKSJJp/rGPT0g1gHDRGSQiITgdPQt8XNNTRIRwWkj36qqD/q7nuao6t2qmqKqaTh/149UtdN+ylXVfGC/iIzwrJoNbPFjSc3ZB0wTkXDP/xOz6aQd6o0sAa7zLF8HvOnHWpolInNxmkcvVtUqf9fTHFXdqKp9VTXN8+8tG5jk+X/6lPTogPB0Qt0KLMP5B/aqqm72b1XNmgFci/Np/CvP14X+Lqob+RHwoohsACYAv/VzPV55rnJeAzKBjTj/jjvVtBAi8jKwGhghItki8n3gAeB8EdmBcxX0gD9rPKKJWv8KRAHve/6dPeHXIhtool7f/KzOfeVkjDHGX3r0FYQxxpimWUAYY4zxygLCGGOMVxYQxhhjvLKAMMYY45UFhDGdgIjM6goz3pqexQLCGGOMVxYQxrSBiCwUkbWewVNPep53USEiD3mez/ChiCR49p0gImsaPFOgt2f9UBH5QETWi0imiAzxvH1kg+dRvOgZJW2M31hAGNNKIjIKuAKYoaoTABdwDRABpKvqGOBT4BeeQ54HfuZ5psDGButfBB5T1fE4cygdmeF0IvBjnGeTDMYZOW+M3wT5uwBjupDZwGRgnefDfS+cCefcwD89+7wA/NvzfIlYVf3Us/454F8iEgUkq+obAKpaDeB5v7Wqmu15/RWQBqz0/a9ljHcWEMa0ngDPqepxTxcTkXsb7Xey89fUNFh2Yf8+jZ9ZE5Mxrfch8G0R6QtHn7E8EOff0bc9+1wNrFTVUqBYRGZ61l8LfOp5EmC2iFzieY9Qz3z+xnQ69gnFmFZS1S0icg+wXEQCgDrgFpyHC031bDuI008BzpTWT3gCYDdwg2f9tcCTInK/5z2+04G/hjGtZrO5GnOKRKRCVSP9XYcx7c2amIwxxnhlVxDGGGO8sisIY4wxXllAGGOM8coCwhhjjFcWEMYYY7yygDDGGOPV/wfI+EMqFt8u2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLpWRfDoXFPm"
      },
      "source": [
        "# 평가용 데이터와 모델에 기반한 예측을 수행함.\n",
        "y_test_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHOWkmx7XGtG",
        "outputId": "9bee5eb8-b280-40a6-c4b9-c01cea9fffba"
      },
      "source": [
        "# roc_auc_score : ROC 곡선 아래 면적에 기반한 점수, TPR이나 FPR을 복합적으로 고려하여 평가함.\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test, y_test_pred, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9462876175727911"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJj1P3ygXIu0"
      },
      "source": [
        "#predicting test_data\n",
        "y_pred = model.predict(train_test_data[ntrain:ntrain+25000 , :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxpEvvtWXKlZ"
      },
      "source": [
        "# 0.5 cutoff를 사용함. 하이퍼파라미터이므로 바뀔 수 있음.\n",
        "predictions = [1 if (x>0.5) else 0 for x in y_pred ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7xYI4akXRV_"
      },
      "source": [
        "predictions = pd.Series(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsWDYSqGXSjQ"
      },
      "source": [
        "ids = raw_test_data['id'].str.replace('\"', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFWPAtzHXUci"
      },
      "source": [
        "submission = pd.DataFrame({'id': ids, 'sentiment':predictions})\n",
        "submission.to_csv('word2vec_model2.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}